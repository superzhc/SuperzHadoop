package com.github.superzhc.hadoop.flink.table;

import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.EnvironmentSettings;
import org.apache.flink.table.api.TableEnvironment;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import java.util.Arrays;

/**
 * @author superz
 * @create 2021/11/1 13:23
 */
public class TableCatalog {
    public static void main(String[] args) {
//        StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
//        EnvironmentSettings settings= EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();
//        StreamTableEnvironment tEnv=StreamTableEnvironment.create(env,settings);
//
//        System.out.println(Arrays.toString(tEnv.listCatalogs()));
//        System.out.println(Arrays.toString(tEnv.listDatabases()));
//        System.out.println(Arrays.toString(tEnv.listFunctions()));
//        System.out.println(Arrays.toString(tEnv.listTables()));
//        System.out.println(Arrays.toString(tEnv.listModules()));
//        System.out.println(Arrays.toString(tEnv.listViews()));
//        System.out.println(Arrays.toString(tEnv.listTemporaryTables()));
//        System.out.println(Arrays.toString(tEnv.listTemporaryViews()));
//        System.out.println(Arrays.toString(tEnv.listUserDefinedFunctions()));
    }
}
