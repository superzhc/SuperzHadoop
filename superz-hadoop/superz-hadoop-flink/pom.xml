<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>superz-hadoop</artifactId>
        <groupId>com.github.superzhc</groupId>
        <version>0.3.0</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>superz-hadoop-flink</artifactId>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
        <scala.binary.version>2.12</scala.binary.version>
        <scala.version>2.12.10</scala.version>
        <mysql.version>8.0.21</mysql.version>
        <cdc.mysql.version>1.3.0</cdc.mysql.version>
        <jedis.version>3.3.0</jedis.version>
    </properties>

    <dependencies>
        <!-- 从 1.11 版本开始，不管是 Java API 还是 Scala API，都需要引用下面的包 -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-clients</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>

        <!--单独DataStream Java接口-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>-->

        <!--单独DataStream Scala接口，不支持2.11版本的scala-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-scala_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>-->

        <!--单独Table Java接口-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>-->

        <!--单独Table Scala接口-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-scala_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>-->

        <!--Table API+DataStream混合 Java 接口-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java-bridge</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>

        <!--Table API+DataStream混合 Scala 接口-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-scala-bridge_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>provided</scope>
        </dependency>-->

        <!--region 通过简单地执行主类来运行作业，需要添加如下的依赖包-->

        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-runtime</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>

        <!--对于 Table API-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-runtime</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-planner-loader</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>

        <!--endregion 通过简单地执行主类来运行作业，需要添加如下的依赖包-->

        <!--Flink 任务是可以在 Idea 中真正执行起来的，但是 WebUI 通常是无法打开的，会提示 `{errors:["Not found"]}`，这是因为缺少了相关的 jar 包，添加如下依赖即可使用 Web UI-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-runtime-web</artifactId>
            <version>${flink.version}</version>
            <!--<scope>provided</scope>-->
        </dependency>

        <!--region 用于测试的依赖-->

        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-test-utils</artifactId>
            <version>${flink.version}</version>
            <scope>test</scope>
            <exclusions>
                <exclusion>
                    <artifactId>log4j-slf4j-impl</artifactId>
                    <groupId>org.apache.logging.log4j</groupId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-test-utils</artifactId>
            <version>${flink.version}</version>
            <scope>test</scope>
        </dependency>

        <!--endregion 用于测试的依赖-->

        <!--CEP-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-cep</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!--region connector-->

        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-base</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-kafka</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <!--2021年10月24日 github relase下载的jar包，Flink相关接口还是老的，存在问题，直接copy下来代码，引入javafaker依赖包-->
        <!--<dependency>
            <groupId>com.github.knaufk</groupId>
            <artifactId>flink-faker</artifactId>
            <version>0.3.0</version>
            <scope>system</scope>
            <systemPath>${project.basedir}/libs/flink-faker-0.3.0.jar</systemPath>
        </dependency>-->
        <!--2021年10月25日 新增 JDBC 数据源操作-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-jdbc</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>${mysql.version}</version>
        </dependency>
        <dependency>
            <groupId>com.alibaba.ververica</groupId>
            <artifactId>flink-connector-mysql-cdc</artifactId>
            <version>${cdc.mysql.version}</version>
        </dependency>

        <!--s3文件系统，注意：本地环境下测试这两个包不能共存-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-files</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <!--如果要在 S3 中使用 checkpoint，推荐使用 Presto S3 文件系统。-->
        <!--<dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-s3-fs-presto</artifactId>
            <version>${flink.version}</version>
        </dependency>-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-s3-fs-hadoop</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!--iceberg-->
        <dependency>
            <groupId>org.apache.iceberg</groupId>
            <artifactId>iceberg-flink-runtime-${flink.major.version}</artifactId>
            <version>${iceberg.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop.version}</version>
            <exclusions>
                <exclusion>
                    <artifactId>hadoop-common</artifactId>
                    <groupId>org.apache.hadoop</groupId>
                </exclusion>
            </exclusions>
        </dependency>

        <!--Mqtt客户端-->
        <dependency>
            <groupId>org.eclipse.paho</groupId>
            <artifactId>org.eclipse.paho.client.mqttv3</artifactId>
            <version>1.2.2</version>
        </dependency>

        <!--Redis客户端-->
        <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>${jedis.version}</version>
        </dependency>
        <!--endregion-->

        <!--region 工程其他模块工具类-->
        <dependency>
            <groupId>com.github.superzhc</groupId>
            <artifactId>superz-common-core</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>com.github.superzhc</groupId>
            <artifactId>superz-common-faker</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>com.github.superzhc</groupId>
            <artifactId>superz-data-core</artifactId>
            <version>${project.version}</version>
        </dependency>
        <!--endregion-->
    </dependencies>

</project>