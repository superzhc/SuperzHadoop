# 安装部署

> Airflow 版本：2.6.3
>
> 前提：
>
> - Python3 的环境，官方测试了  Python 3.7, 3.8, 3.9, 3.10
> - 数据库：
>   - PostgreSQL: 11, 12, 13, 14, 15
>   - MySQL: 5.7, 8
>   - SQLite: 3.15.0+
>   - MSSQL(Experimental): 2017, 2019

## 本地安装

### 1. **设置 Airflow Home**【可选】

Airflow 要求一个主目录，如果未设置，默认使用 `~/airflow`，若不使用默认路径，可通过设置环境 `AIRFLOW_HOME` 来指定 Airflow 主目录。

**Linux**

```sh
export AIRFLOW_HOME=~/airflow
```

**Windows PowerShell**

```sh
#Powershell设置环境变量

#查看所有环境变量，注意后面的冒号
ls env:

#搜索环境变量   
ls env:NODE*

#查看单个环境变量 
$env:NODE_ENV

#添加/更新环境变量 
$env:NODE_ENV=development

#删除环境变量        
del evn:NODE_ENV
```

```sh
$env:AIRFLOW_HOME="D:\\soft\\airflow"
```

### 2. **使用约束文件安装 Airflow**

**Linux**

```sh
AIRFLOW_VERSION=2.6.3

# Extract the version of Python you have installed. If you're currently using Python 3.11 you may want to set this manually as noted above, Python 3.11 is not yet supported.
PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"

CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"
# For example this would install 2.6.3 with python 3.7: https://raw.githubusercontent.com/apache/airflow/constraints-2.6.3/constraints-3.7.txt

pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
```

**Windows**

```sh
# 根据实际的Python及Airflow版本获取约束文件
pip install "apache-airflow==2.6.3" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.6.3/constraints-3.9.txt"
```

### 3. **启动**

> 默认 Airflow 会在 `$AIRFLOW_HOME` 目录下创建默认 `airflow.cfg` 配置文件，用户可使用环境变量来覆盖掉默认配置。

~~**运行 Airflow Standalone**~~

`airflow standalone` 命令会初始化数据库，创建用户和启动所有组件

**手动运行各部分**

```sh
airflow db init

airflow users create \
    --username admin \
    --firstname Peter \
    --lastname Parker \
    --role Admin \
    --email spiderman@superhero.org

airflow webserver --port 8080

airflow scheduler
```

### 4. 访问 Airflow UI

浏览器访问 `localhost:8080`

## Docker 安装【单容器】

[Dockerhub 镜像地址](https://hub.docker.com/r/apache/airflow)：<https://hub.docker.com/r/apache/airflow>

### **拉取镜像**

```sh
docker pull apache/airflow:2.6.3-python3.9
```

### **启动镜像**

```sh
docker run -dit --name airflow --network all -p 8080:8080 -v /d/wsl/docker/volumes/airflow/dags:/opt/airflow/dags -v /d/wsl/docker/volumes/airflow/logs:/opt/airflow/logs apache/airflow:2.6.3-python3.9 bash
```

> 注意：
> 
> 1. 连接外部数据源需要配置网络，即参数 `--network all`
> 2. 运行一个前台进程挂着，保证 airflow 容器不会自动退出

### **进入容器**

```sh
docker exec -it airflow bash
```

#### 容器执行命令

**初始化数据库**

```sh
airflow db init
```

> 执行上述命令来保证生成 `airflow.cfg` 文件，修改 `airflow.cfg` 来切换数据库。

1. ~~删除 `airflow.db` 文件~~
2. 配置数据库连接参数：`sql_alchemy_conn = mysql+mysqldb://airflow:airflow@mysql8:3306/airflow_docker`
3. 重新执行初始化数据库命令：`airflow db init`

**创建用户**

```sh
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname Admin \
    --role Admin \
    --email airflowadmin@example.com
```

**启动 Web UI**

```sh
airflow webserver --port 8080

# 后端启动
airflow webserver --port 8080 -D &
```

**启动 Scheduler**

```sh
nohup airflow scheduler &
```

## Docker Compose 安装【未验证】

> [docker-compose.yaml](https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml)

### 初始化数据库

```sh
docker compose up airflow-init
```

### 启动 Airflow

```sh
docker compose up
```