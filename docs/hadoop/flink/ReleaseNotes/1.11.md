# Flink1.11 发行说明【翻译】

> 官网原文：<https://ci.apache.org/projects/flink/flink-docs-release-1.11/zh/release-notes/flink-1.11.html>

## Clusters & Deployment

### 支持 Hadoop3.0.0 及更高的版本

Flink 不再提供 `flink-shaded-hadoop-*` 依赖包。用户若需要 Hadoop 依赖包，可以通过设置 `HADOOP_CLASSPATH` 环境变量（推荐）或者在 `\lib` 文件夹下放入 Hadoop 依赖项。同时 `include-hadoop` Maven profile 已经被移除了。

### `slave` 文件重命名为 `workers`

对于 Standalone 模式，worker 节点文件不再配置 `slaves` 而是配置文件 `workers`。以前使用 `start-cluster.sh` 和 `stop-cluster.sh` 脚本的设置需要重命名该文件。

## Memory Management

### 新 JobManager 内存模型

伴随 [FLIP-116](https://cwiki.apache.org/confluence/display/FLINK/FLIP-116%3A+Unified+Memory+Configuration+for+Job+Managers)，为 JobManager 引入了新的内存模型。引入了新的配置选项来控制 JobManager 进程的内存消耗。这影响到所有类型的部署模式：standalone，YARN，Mesos 以及最新集成的 Kubernetes。

> 请，通过用户手册见[更多详细内容](https://ci.apache.org/projects/flink/flink-docs-master/ops/memory/mem_setup_jobmanager.html)。

如果尝试在没有任何调整的情况下重用以前的 Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能变化甚至失败。为了启动 JobManager 进程，必须至少指定以下选项之一：`jobmanager.memory.flink.size`，`jobmanager.memory.process.size` 或 `jobmanager.memory.heap.size`。

**弃用和重大的变更**

以下的选项被废弃：

- `jobmanager.heap.size`
- `jobmanager.heap.mb`

如果仍然使用这些不建议使用的选项，则它们将被解释为以下新选项之一，以便保持向后兼容性：

- 对于 standalone 和 Mesos 部署模式：JVM Heap (`jobmanager.memory.heap.size`) 
- 对于容器部署模式（Kubernetes、Yarn）：Total Process Memory (`jobmanager.memory.process.size`)

以下选项已经被移除并且不再起任何效果：

- `containerized.heap-cutoff-ratio`
- `containerized.heap-cutoff-min`

JVM 参数

JobManager 的 JVM 进程的 direct 和 metaspace 内存通过以下参数控制

- `jobmanager.memory.off-heap.size`
- `jobmanager.memory.jvm-metaspace.size`

## Table API & SQL

### Blink 是现在默认的 planner [FLINK-16934](https://issues.apache.org/jira/browse/FLINK-16934)

现在默认的 table planner 已经改变成 Blink

### Table API 包结构变更 [FLINK-15947](https://issues.apache.org/jira/browse/FLINK-15947)

由于软件包 `org.apache.flink.table.api.scala/java` 的各种问题，这些软件包中的所有类都已重定位。此外，如 Flink 1.9 中所述，scala 表达式已移至 `org.apache.flink.table.api`。

如果你之前使用下面的类：

- `org.apache.flink.table.api.java.StreamTableEnvironment`
- `org.apache.flink.table.api.scala.StreamTableEnvironment`
- `org.apache.flink.table.api.java.BatchTableEnvironment`
- `org.apache.flink.table.api.scala.BatchTableEnvironment`

并且你不需要进行 DataStream 转换，使用如下的包：

```java
org.apache.flink.table.api.TableEnvironment
```

如果你需要进行 DataStream/DataSet 转换，进行如下包引用的改变：

- `org.apache.flink.table.api.bridge.java.StreamTableEnvironment`
- `org.apache.flink.table.api.bridge.scala.StreamTableEnvironment`
- `org.apache.flink.table.api.bridge.java.BatchTableEnvironment`
- `org.apache.flink.table.api.bridge.scala.BatchTableEnvironment`

对于 Scala 表达式，使用如下的引用：

```scala
org.apache.flink.table.api._ instead of org.apache.flink.table.api.bridge.scala._
```

另外，如果你使用 DataStream/DataSet 之间的隐式转换，请导入：

```scala
org.apache.flink.table.api.bridge.scala._ instead of org.apache.flink.table.api.scala._
```

### 删除已弃用的 `StreamTableSink` [FLINK-16362](https://issues.apache.org/jira/browse/FLINK-16362)

### 删除已弃用的 `BatchTableSink#emitDataSet` [FLINK-16535](https://issues.apache.org/jira/browse/FLINK-16535)

### 纠正 `TableEnvironment.execute()` 和 `StreamTableEnvironment.execute()` 的执行行为 [FLINK-16363](https://issues.apache.org/jira/browse/FLINK-16363)

在早期的版本， `TableEnvironment.execute()` 和 `StreamExecutionEnvironment.execute()` 都可以触发 Table 程序和 DataStream 程序。从 Flink 1.11.0 开始，Table 程序只能由 `TableEnvironment.execute()` 触发。将 Table 程序转换为 DataStream 程序（通过 `toAppendStream()` 或 `toRetractStream()` 方法）后，只能由 `StreamExecutionEnvironment.execute()` 触发它。

### 纠正 `ExecutionEnvironment.execute()` 和 `BatchTableEnvironment.execute()` 的执行行为 [FLINK-17126](https://issues.apache.org/jira/browse/FLINK-17126)

在早期的版本中， `BatchTableEnvironment.execute()` 和 `ExecutionEnvironment.execute()` 都可以触发 Table 和 DataSet 应用程序（针对老的 planner）。 从 Flink 1.11.0 开始，批处理 Table 程序只能由 `BatchEnvironment.execute()` 触发。将 Table 程序转换为 DataSet 程序（通过 `toDataSet()` 方法）后，只能由 `ExecutionEnvironment.execute()` 触发它。

## Configuration

### 重命名 `log4j-yarn-session.properties` 和 `logback-yarn.xml` 配置文件 [FLINK-17527](https://issues.apache.org/jira/browse/FLINK-17527)

日志配置文件 `log4j-yarn-session.properties` 和 `logback-yarn.xml` 已经重命名为 `log4j-session.properties` 和 `logback-session.xml`。而且，`yarn-session.sh` 和 `kubernetes-session.sh` 都使用这些日志配置文件。

## State

TODO