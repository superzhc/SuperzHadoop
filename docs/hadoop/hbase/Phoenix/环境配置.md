### 环境配置

#### 1、设置  `HADOOP_CONF_DIR`

Phoenix 需要读取 HBase 集群所使用的 HDFS 环境。若 Phoenix 所在的服务器在 HDFS 的 node 上，则可直接指定为 `$HADOOP_HOME/conf` 目录，主要是读取该目录下的 `core-site.xml`、`hdfs-site.xml` 这两个文件。若不在 HDFS 的 node 上，需要到服务器上将这 2 个配置文件拷贝下来，配置所需要的参数。

#### 2、设置 `HBASE_CONF_DIR`

Phoenix 需要配置相关参数才能访问 HBase 集群。若 Phoenix 所在的服务器在 HBase 的 Master/RegionServer 上，则可直接配置 `$HBASE_HOME/conf` 目录，读取的是 `hbase-site.xml` 文件，该文件配置了访问 HBase 服务相关参数。若不在 HBase 的节点上，需要单独添加 `hbase-site.xml` 文件，添加 HBase 以及 HDFS 的相关配置项即可

#### 3、设置 `LD_LIBRARY_PATH`【可选】

如果HBase开启了Lzo/Snappy等压缩方式，需要指定客户端上的LD_LIBRARY_PATH环境变量来加载本地库，否则会出现数据读写异常。

#### 4、使用 Phoenix 的客户端 Jar 包

若用户需要使用 Phoenix 的 JDBC 方式来访问 HBase，只需要 `phoenix-4.x-HBase-1.x-client.jar` 这个 Jar 就可以了。这个Jar 包就在 Phoenix 的发行包下，将其添加到你的 Java 应用程序的 ClassPath 即可，访问 HBase 所需要的其他类都已经被包含在其中。需要注意的是，若直接使用 hadoop jar 方式来调用，在Hadoop版本不一致的情况下，可能会存在某些jar包版本冲突的风险。这时可以使用java直接来调用。