# 示例代码

## Write

**Scala 版本**

```scala
import org.apache.hudi.QuickstartUtils._
import org.apache.hudi.DataSourceReadOptions._
import org.apache.hudi.DataSourceWriteOptions._
import org.apache.hudi.config.HoodieWriteConfig._

import scala.collection.JavaConversions._

import org.apache.spark.sql.Row

import org.apache.spark.sql.types._
import org.apache.spark.sql.SaveMode._

val tableName = "hudi_trips_cow"
val basePath = "file:///tmp/hudi_trips_cow"
val schema = StructType( Array(
    StructField("rowId", StringType,true),
    StructField("partitionId", StringType,true),
    StructField("preComb", LongType,true),
    StructField("name", StringType,true),
    StructField("versionId", StringType,true),
    StructField("intToLong", IntegerType,true)
    ))

val data1 = Seq(Row("row_1", "part_0", 0L, "bob", "v_0", 0),
                Row("row_2", "part_0", 0L, "john", "v_0", 0),
                Row("row_3", "part_0", 0L, "tom", "v_0", 0))

var dfFromData1 = spark.createDataFrame(data1, schema)

// 待完善
dfFromData1.write.format("hudi").
       options(getQuickstartWriteConfigs).
       option(PRECOMBINE_FIELD_OPT_KEY.key, "preComb").
       option(RECORDKEY_FIELD_OPT_KEY.key, "rowId").
       option(PARTITIONPATH_FIELD_OPT_KEY.key, "partitionId").
       option("hoodie.index.type","SIMPLE").
       option(TABLE_NAME.key, tableName).
       mode(Overwrite).
       save(basePath)
```

## Read

**Scala 版本**

```scala
val basePath = "file:///tmp/hudi_trips_cow"
var tripsSnapshotDF1 = spark.read.format("hudi").load(basePath + "/*/*")
tripsSnapshotDF1.createOrReplaceTempView("hudi_trips_snapshot")
spark.sql("desc hudi_trips_snapshot").show()
spark.sql("select rowId, partitionId, preComb, name, versionId, intToLong from hudi_trips_snapshot").show()
```