# 缓存与持久化机制

对 DStream 调用 `persist()` 方法，就可以让 Spark Streaming 自动将该数据流中的所有产生的 RDD，都持久化到内存中。

对于**基于窗口的操作**，比如 reduceByWindow、reduceByKeyAndWindow，以及基于状态的操作，比如 updateStateByKey，默认就**隐式开启了持久化机制**

对于通过**网络接收数据**的输入流，比如 socket、Kafka、Flume 等，默认的持久化级别是将**数据复制**一份，以便于容错，用的是类似 MEMORY_ONLY_SER_2

默认的持久化级别，统一都是要序列化的