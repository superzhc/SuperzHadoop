## checkpoint

updateStateByKey、window 等有状态的操作，自动进行 checkpoint，必须设置 checkpoint 目录

```scala
val ssc =  new StreamingContext(spark.sparkContext,Seconds(1))
//必须checkpoint
ssc.checkpoint("hdfs://spark1:9000/checkpoint")  
```

## Driver 高可用性

第一次在创建和启动 StreamingContext 的时候，将元数据写入容错的文件系统（比如hdfs），Driver 挂掉后可以从容错文件系统（比如 hdfs）中读取之前的元数据信息，包括 Job 的执行进度，继续接着之前的进度

前提条件：cluster 模式(Driver 运行在 Worker)

```java
JavaStreamingContextFactory contextFactory = new JavaStreamingContextFactory() {
  @Override 
  public JavaStreamingContext create() {
    JavaStreamingContext jssc = new JavaStreamingContext(...);  
    JavaDStream<String> lines = jssc.socketTextStream(...);     
    jssc.checkpoint(checkpointDirectory);                       
    return jssc;
  }
};
//getOrCreate
JavaStreamingContext context = JavaStreamingContext.getOrCreate(checkpointDirectory, contextFactory);
context.start();
context.awaitTermination();
```

提交任务的命令也需要相应的参数：

```bash
spark-submit --deploy-mode cluster --supervise
```

## RDD 高可用性：启动 WAL 预写日志机制

一个 batch 创建一个 RDD，启用预写日志后 Receiver 接收到数据后，就会立即将数据写入一份到容错文件系统（比如 HDFS）上的 checkpoint 目录中去

```properties
spark.streaming.receiver.writeAheadLog.enable=true
```