# 预写日志机制

如果启用该机制，Receiver 接收到的所有数据都会被写入配置的 Checkpoint 目录中的预写日志。这种机制可以让 Driver 在恢复的时候，避免数据丢失，并且可以确保整个实时计算过程中，零数据丢失。

**缺点**

会导致 Receiver 的吞吐量大幅度下降，因为单位时间内，有相当一部分时间需要将数据写入预写日志。

## 使用方式

1. StreamingContext 的 `checkpoint()` 方法设置一个 checkpoint 目录
2. `spark.streaming.receiver.writeAheadLog.enable=true`

## 优化

1. 创建多个输入 DStream，启动多个 Rceiver
  > 注意cpu core数量
2. 禁用复制持久化机制，因为所有数据已经保存在容错的文件系统中了
    DStream默认持久化机制为 `StorageLevel.MEMORY_AND_DISK_SER_2`，改为 `StorageLevel.MEMORY_AND_DISK_SER`