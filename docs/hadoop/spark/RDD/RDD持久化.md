Spark 最重要的一个功能是它可以通过各种操作持久化（或者缓存）一个集合到内存中。当持久化一个 RDD 的时候，每一个节点都将参与计算的所有分区数据存储到内存中，并且这些数据可以被这个集合（以及这个集合衍生的其他集合）的动作（action）重复利用。这个能力使后续的动作速度更快（通常快 10 倍以上）。对应迭代算法和快速的交互使用来说，缓存是一个关键的工具。

通过 `persist()` 或者 `cache()` 方法持久化一个 RDD。首先，在 action 中计算得到 RDD；然后，将其保存在每个节点的内存中。Spark 的缓存是一个容错的技术，如果 RDD 的任何一个分区丢失，它可以通过原有的*转化操作*自动的重复计算并且创建出这个分区。

此外，用户可以利用不同的存储级别存储每一个被持久化的 RDD。例如，它允许用户持久化集合到磁盘上、将集合作为序列化的 Java 对象持久化到内存中、在节点间复制集合或者存储集合到 Tachyon 中。用户可以通过传递一个 `StorageLevel` 对象给 `persist()` 方法设置这些存储级别。`cache()` 方法使用了默认的存储级别—`StorageLevel.MEMORY_ONLY`。

## Spark的持久化级别

|               持久化级别                |                           含义解释                           |
| :-------------------------------------: | :----------------------------------------------------------: |
|               MEMORY_ONLY               | 使用未序列化的 Java 对象格式，将数据保存在内存中。如果内存不够存放所有的数据，则数据可能就不会进行持久化。那么下次对这个 RDD 执行算子操作时，那些没有被持久化的数据，需要从源头处重新计算一遍。这是默认的持久化策略，使用 `cache()` 方法时，实际就是使用的这种持久化策略。 |
|             MEMORY_AND_DISK             | 使用未序列化的 Java 对象格式，优先尝试将数据保存在内存中。如果内存不够存放所有的数据，会将数据写入磁盘文件中，下次对这个 RDD 执行算子时，持久化在磁盘文件中的数据会被读取出来使用。 |
|             MEMORY_ONLY_SER             | 基本含义同 MEMORY_ONLY。唯一的区别是，会将 RDD 中的数据进行序列化，RDD 的每个 partition 会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁 GC。 |
|           MEMORY_AND_DISK_SER           | 基本含义同 MEMORY_AND_DISK。唯一的区别是，会将 RDD 中的数据进行序列化，RDD 的每个 partition 会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁 GC。 |
|                DISK_ONLY                |    使用未序列化的 Java 对象格式，将数据全部写入磁盘文件中。    |
| MEMORY_ONLY_2, MEMORY_AND_DISK_2 等等 | 对于上述任意一种持久化策略，如果加上后缀 `_2`，代表的是将每个持久化的数据，都复制一份副本，并将副本保存到其他节点上。这种基于副本的持久化机制主要用于进行容错。假如某个节点挂掉，节点的内存或磁盘中的持久化数据丢失了，那么后续对 RDD 计算时还可以使用该数据在其他节点上的副本。如果没有副本的话，就只能将这些数据从源头处重新计算一遍了。 |
| OFF_HEAP (experimental)                | 以序列化的格式存储 RDD 到[Tachyon](http://tachyon-project.org/)中。相对于 MEMORY_ONLY_SER，OFF_HEAP 减少了垃圾回收的花费，允许更小的执行者共享内存池。这使其在拥有大量内存的环境下或者多并发应用程序的环境中具有更强的吸引力。 |


Spark 也会自动持久化一些 Shuffle 操作（如`reduceByKey`）中的中间数据，即使用户没有调用 `persist` 方法。这样的好处是避免了在 shuffle 出错情况下，需要重复计算整个输入。如果用户计划重用计算过程中产生的 RDD，仍然推荐用户调用 `persist` 方法。

## 如何选择一种最合适的持久化策略

1. 认情况下，性能最高的当然是 MEMORY_ONLY，但前提是内存必须足够足够大，可以存放下整个 RDD 的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个 RDD 的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果 RDD中 数据比较多时（比如几十亿），直接用这种持久化级别，会导致JVM 的 OOM 内存溢出异常。
2. 如果使用 MEMORY_ONLY 级别时发生了内存溢出，那么建议尝试使用 MEMORY_ONLY_SER 级别。该级别会将 RDD 数据序列化后再保存在内存中，此时每个 partition 仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比 MEMORY_ONLY 多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上，如果 RDD 中的数据量过多的话，还是可能会导致 OOM 内存溢出的异常。
3. 如果纯内存的级别都无法使用，那么建议使用 MEMORY_AND_DISK_SER 策略，而不是 MEMORY_AND_DISK 策略。因为既然到了这一步，就说明 RDD 的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。
4. 通常不建议使用 DISK_ONLY 和后缀为_2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有 RDD。后缀为_2的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。

## 删除数据

Spark 自动的监控每个节点缓存的使用情况，利用最近*最少使用原则*删除老旧的数据。如果想手动的删除 RDD 缓存数据，可以使用 `RDD.unpersist()` 方法。