## 从 `Hadoop+Storm` 架构转向 Spark 架构

为了能同时进行批处理与流处理，企业应用中通常会采用 `Hadoop+Storm` 的架构（也称为Lambda架构）。下图给出了采用 `Hadoop+Storm` 部署方式的一个案例，在这种部署架构中，Hadoop 和 Storm 框架部署在资源管理框架 YARN（或Mesos）之上，接受统一的资源管理和调度，并共享底层的数据存储（HDFS、HBase、Cassandra等）。Hadoop 负责对批量历史数据的实时查询和离线分析，而 Storm 则负责对流数据的实时处理。

<img src="../images/图9-14-采用HadoopStorm部署方式的一个案例.jpg" alt="图9-14  采用“Hadoop+Storm”部署方式的一个案例" style="zoom: 67%;" />

但是，上面这种架构部署较为繁琐。由于 Spark 同时支持批处理与流处理，因此，对于一些类型的企业应用而言，从 `Hadoop+Storm` 架构转向Spark架构（如下图所示）就成为一种很自然的选择。采用Spark架构具有如下优点：

- 实现一键式安装和配置、线程级别的任务监控和告警；
- 降低硬件集群、软件维护、任务监控和应用开发的难度；
- 便于做成统一的硬件、计算平台资源池。

需要说明的是，Spark Streaming 的原理是将流数据分解成一系列短小的批处理作业，每个短小的批处理作业使用面向批处理的Spark Core 进行处理，通过这种方式变相实现流计算，而不是真正实时的流计算，因而通常无法实现毫秒级的响应。因此，对于需要毫秒级实时响应的企业应用而言，仍然需要采用流计算框架（如Storm）。

<img src="../images/图9-15-用Spark架构满足批处理和流处理需求.jpg" alt="图9-15 用Spark架构同时满足批处理和流处理需求" style="zoom:67%;" />

## Hadoop和Spark的统一部署

一方面，由于 Hadoop 生态系统中的一些组件所实现的功能，目前还是无法由 Spark 取代的，比如，Storm可以实现毫秒级响应的流计算，但是，Spark 则无法做到毫秒级响应。另一方面，企业中已经有许多现有的应用，都是基于现有的 Hadoop 组件开发的，完全转移到 Spark 上需要一定的成本。因此，在许多企业实际应用中，Hadoop 和 Spark 的统一部署是一种比较现实合理的选择。
由于 Hadoop MapReduce、HBase、Storm 和Spark 等，都可以运行在资源管理框架 YARN 之上，因此，可以在 YARN 之上进行统一部署（如下图所示）。这些不同的计算框架统一运行在YARN中，可以带来如下好处：

- 计算资源按需伸缩；
-  不用负载应用混搭，集群利用率高；
- 共享底层存储，避免数据跨集群迁移。

![图9-16 Hadoop和Spark的统一部署](../images/图9-16-Hadoop和Spark的统一部署.jpg)